---
title: "Calgary Airport Reference ET - ACIS Data"
author: "Colin Hansen, M.Eng., P. Eng."
date: "March-2021"
# https://stackoverflow.com/questions/25849814/rstudio-rmarkdown-both-portrait-and-landscape-layout-in-a-single-pdf/41945462#41945462
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}

output:
  
  pdf_document: default
  word_document: default
  
# latex_engine: xelatex

# output:
#   word_document: default
#   html_notebook: default
#   pdf_document: default
#   html_document:
#     df_print: paged
    
---

##Project Description

Compute the reference ET for the Calgary Airport CS station. 

Raw climate and solar radiation data was obtained from the Alberta Climate Information Service:

https://acis.alberta.ca/acis/weather-data-viewer.jsp




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# note to self; load 'plyr' before 'dplyr' / 'tidyverse'; see page 151 ' R for Everyone'

library(plyr)
library(tidyverse)
# note: tidyverse includes 'dplyr' package but not 'plyr'

library(printr)
library(reshape2)
library(pander)

library(lubridate)
library(scales)
library(rio)
library(knitr)
library(tinytex)
library(ggnewscale)
library(hydroTSM)
library(cowplot)
library(flextable)
library(officer) #see page 30 'flextable' package
# library(readxl)

panderOptions('knitr.auto.asis', FALSE)


```




```{r read-and-process-raw-data, eval = TRUE, include=FALSE}

# remove all the files saved from the previous session
rm(list=ls())


      # create directory to save the ET results
      ET_folder_1<-'data_out/Ref_ET_Results_1'
      
      # create (if necessary) directory - ** first part
      if(dir.exists(ET_folder_1) == FALSE) dir.create(ET_folder_1)


      # get the names of the raw data files
      raw_data_filenames<-dir('data_in',full.names = TRUE)
      
     
      # raw_data_filenames<-raw_data_filenames[5:9] # TESTING ONLY
     
      
      # enter loop to create a list of the raw data filenames (e.g. ACISDailyData_2016.csv, etc.)
      
      # create empty list
      
      raw_data_filenames_list <- list(NULL)
      
      for (q in seq_along(raw_data_filenames)) {  
      
      # build the list of raw data filenames 
        
      raw_data_filenames_list[q] <- list(raw_data_filenames[q])
      
        } # end of 'seq_along(raw_data_filenames)' 
        
     
  
  
 

  ### function ###
  
  process_raw_file_function <- function(x){
    
    
      # read the ACIS climate data
      climate_daily<-read.csv(x,header = TRUE,sep=",",stringsAsFactors = FALSE)
      
      # rename the second column
      names(climate_daily)[2]<-"Date"
      
      # force the dates to be class character - ** disabled for now **
      # climate_daily$Date <- as.character(climate_daily$Date) 
      
      
      # create Dates from character strings
      dformat<-"%d-%b-%y"
      climate_daily$Date<-as.Date(climate_daily$Date,dformat)
      climate_daily<- climate_daily[,c(1,2,3,5,8,11,14,17)]
      names(climate_daily) <- c("Station.Name","Date","Tdew","Tmin","Tmax","Tmean","Rs","u10")
      
      # print(str(climate_daily))
      
      
      ## diagnostic only
      climate_daily_df<- climate_daily
      names(climate_daily_df) <- c("Station.Name","Date","Tdew","Tmin","Tmax","Tmean","Rs","u10")

      # view(climate_daily_df)
     
      # convert to tibble
      climate_daily<-as_tibble(climate_daily)
      
      # view(climate_daily)
      
      # add Year / Month / Day / DOY
      climate_daily<-mutate(climate_daily,Year=year(Date),Month=month(Date),Day=mday(Date),DOY=yday(Date))
      
      
      # summarize missing data by column
      Missing.Count<-apply(is.na(climate_daily),2,sum)
      Column.Names<-names(climate_daily)
      missing_data_df<-t(data.frame(Column.Names, Missing.Count))
      write.table(missing_data_df,"ACIS_Missing_Data_Summary.csv",sep=",",col.names=FALSE,row.names=FALSE)
      
      # *** Year 2015 has missing u10 wind data ** replace with YYC 30 year normal of 16.1 km/hr ***
      # ** Unused here but keep for now
    
      # u10_missing<-is.na(climate_daily$u10)
      # climate_daily$u10[u10_missing]<-16.1
      
      # adjust wind speed units from km/hr to m/s
      climate_daily<-mutate(climate_daily,u10=u10*(1000/3600))
      
      # adjust wind speed to 2m height ** Eq. (S5.20 McMahon)
      z<-10
      climate_daily<-mutate(climate_daily,u2=u10*(4.87/(log(67.8*z-5.42))))
      
      # adjust Rs from(W/m2/day) to (MJ/m2/day)
      climate_daily<-mutate(climate_daily,Rs=Rs*0.0864)
      
      #
      # >>> Start Reference ET Calculations <<<
      #
      # general constants
      
      solar_constant_Gsc<-0.0820
      Stef_Boltz<-4.903E-9
      latent_heat_vap<-2.45
      mean_density_air<-1.20
      specific_heat_air<-0.001013
      mean_density_water<-997.9
      specific_heat_water<-0.00419
      albedo_ref_crop<-0.23 #short grass
    
      # project specific constants and data
      # location = Calgary Intl CS
      stn_lat_rad<-0.892034
      stn_elev_m<-1081
      
      # intermedidate calculations
      
      climate_daily<-mutate(climate_daily,svp_Tmax=0.6108*exp((17.27*Tmax)/(Tmax+237.3)))
      climate_daily<-mutate(climate_daily,svp_Tmin=0.6108*exp((17.27*Tmin)/(Tmin+237.3)))
      climate_daily<-mutate(climate_daily,daily_svp=((svp_Tmax+svp_Tmin)/2))
      climate_daily<-mutate(climate_daily,mean_daily_avp=0.6108*exp((17.27*Tdew)/(Tdew+237.3)))
      climate_daily<-mutate(climate_daily,slope_svp=4098*(0.6108*exp((17.27*Tmean)/(Tmean+237.3))/(Tmean+237.3)^2))
      climate_daily<-mutate(climate_daily,atm_press=101.3*((293-0.0065*stn_elev_m)/293)^5.26)
      climate_daily<-mutate(climate_daily,psychro_constant=0.00163*(atm_press/latent_heat_vap))
      climate_daily<-mutate(climate_daily,dr2=1+0.033*cos((2*pi)/365*DOY))
      climate_daily<-mutate(climate_daily,solar_decl=0.409*sin((2*pi/365)*DOY - 1.39))
      climate_daily<-mutate(climate_daily,sunset_hour_angle=acos((-tan(stn_lat_rad)*tan(solar_decl))))
      climate_daily<-mutate(climate_daily,Ra=((1440/pi)*solar_constant_Gsc*dr2*((sunset_hour_angle*sin(stn_lat_rad)*sin(solar_decl)+cos(stn_lat_rad)*cos(solar_decl)*sin(sunset_hour_angle)))))
      climate_daily<-mutate(climate_daily,Rso=(0.75+2E-5*stn_elev_m)*Ra)
      climate_daily<-mutate(climate_daily,Rnl=Stef_Boltz*(0.34-0.14*mean_daily_avp^0.5)*((Tmax+273.2)^4+(Tmin+273.2)^4)/2*(1.35*(Rs/Rso)-0.35))
      climate_daily<-mutate(climate_daily,Rns=(1-albedo_ref_crop)*Rs)
      climate_daily<-mutate(climate_daily,Rn=Rns-Rnl)
      # calculate the reference ET radiation term
      climate_daily<-mutate(climate_daily,ET_rad=(0.408*(slope_svp*Rn))/(slope_svp+psychro_constant*(1+0.34*u2)))
      # calculate the reference ET aerodynamic term
      climate_daily<-mutate(climate_daily,ET_aero=(psychro_constant*(900/(Tmean+273)))*u2*(daily_svp-mean_daily_avp)/(slope_svp+psychro_constant*(1+0.34*u2)))
      # reference ET
      climate_daily<-mutate(climate_daily,ET_rc=ET_rad+ET_aero)
      
      
      # extract the four numeric digits which are the year in the filename
      raw_year <- str_extract(x,"[0-9][0-9][0-9][0-9]")
      
    
      # create a file name to save the files for each site (** dynamic **)
      CSV_file_name<-paste0("YYC_Ref_ET_",raw_year,".csv")
      CSV_outfile<-file.path(ET_folder_1, CSV_file_name)
        
      # write the results to .CSV file
      write_csv(climate_daily,CSV_outfile)   
  
            
  }  # end 'process_raw_file_function'
  
  
  
    # use 'map' to apply 'process_raw_file_function' to the list of dataframes
        
    Ref_ET_data_list <- raw_data_filenames_list %>% map(process_raw_file_function)
        
   


```

\clearpage

\blandscape


## Reference ET Statistics ...


```{r ET-stats-part-1, eval= TRUE, echo = FALSE,include = TRUE, message=FALSE, warning=FALSE, results = 'asis'}


    ## generate summary statistics for each year of ET results
      
      # use 'map' to convert the list of tibbles to a list of dataframes

      Ref_ET_data_list_df <- Ref_ET_data_list %>% map(as.data.frame)



      # use 'bind_rows' to combine the list of dataframes to one dataframe
      
      Ref_ET_data_df <- bind_rows(Ref_ET_data_list_df)

      # get the unique Year values; needed to name smry results dataframe
      
      unique_years <- unique(Ref_ET_data_df$Year)
      
      view(unique_years)

    # function to select only the Year

    select_ET_rc <- function(xx){
      
      xx %>% select(ET_rc)
      
      
    } # end of 'select_two_cols' function
    
    
      # use 'map' to apply 'select_ET_rc' to the list of dataframes

      select_ET_rc_list <- Ref_ET_data_list_df %>% map(select_ET_rc)

      
      # use 'bind_cols' to combine the list of dataframes to one dataframe

      ET_rc_only_df <- bind_cols(select_ET_rc_list)

      # view(ET_rc_only_df)
      
      
          
      # assign names to the list
      
      names(select_ET_rc_bind_cols) <- as.character(unique_years)
     
      
   
      # apply 'smry' to the ET_rc dataframe; multiple colunns

      Ref_ET_smry_stats <- hydroTSM::smry(select_ET_rc_bind_cols)
      
     
      # create a file name to save the files for each site
      CSV_file_name<-"Summary_Statistics_YYC Reference_ET.csv"
      CSV_outfile<-file.path(ET_folder_1, CSV_file_name)

      # write the results to .CSV file
      write.table(Ref_ET_smry_stats,CSV_outfile,sep=",",col.names=NA,row.names=TRUE)
     

     
       # use the 'flextable' package to create table
      
      # create table caption (dynamic)
      table_caption<-'Summary Statistics: YYC Reference ET'
      
      # Ref_ET_stats_bind_cols %>%  flextable() %>%
      # set_caption(caption = table_caption) %>%
      # fontsize(size = 10, part = "all") %>%
      # colformat_double(j=c(2:6),digits = 3) %>%
      # colformat_double(i=c(12,13),digits = 0) %>%
      # theme_vanilla() %>%
      # fit_to_width(max_width = 8)
      # autofit()


```


\elandscape
